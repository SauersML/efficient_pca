name: Rust CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  CARGO_TERM_COLOR: always

# Explicitly set permissions for the GITHUB_TOKEN
permissions:
  contents: read  # For actions/checkout
  issues: write   # For creating, closing, and labeling issues

jobs:
  build_test_bench:
    name: Build, Test & Bench (${{ matrix.blas_backend }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false # Allow all matrix jobs to complete to get all reports
      matrix:
        blas_backend: [backend_openblas, backend_mkl, backend_faer]
        include:
          - blas_backend: backend_openblas
            os: ubuntu-latest
            rust_flags: "" 
            backend_feature: backend_openblas
          - blas_backend: backend_mkl
            os: ubuntu-latest 
            rust_flags: "-L/opt/intel/oneapi/mkl/latest/lib/intel64" 
            backend_feature: backend_mkl
          - blas_backend: backend_faer
            os: ubuntu-latest
            rust_flags: ""
            backend_feature: backend_faer
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Rust toolchain
        id: install_rust
        uses: dtolnay/rust-toolchain@nightly
        with:
          toolchain: nightly
          components: ''

      - name: Get Rust compiler version
        id: rust_version
        run: echo "version=$(rustc --version)" >> "$GITHUB_OUTPUT"

      # ------------------------- Python Setup -------------------------
      - name: Set up Python ðŸ
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install Python dependencies ðŸ“¦
        run: |
          python -m pip install --upgrade pip
          pip install numpy scikit-learn scipy
      # ----------------------------------------------------------------

      - name: Install OpenBLAS
        if: matrix.blas_backend == 'backend_openblas'
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y libopenblas-dev
      
      - name: Install Intel MKL and set environment
        if: matrix.blas_backend == 'backend_mkl'
        run: |
          wget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB | sudo gpg --dearmor --output /usr/share/keyrings/intel-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/intel-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main" | sudo tee /etc/apt/sources.list.d/oneAPI.list
          sudo apt-get update -qq
          sudo apt-get install -y intel-oneapi-mkl-devel
          echo "MKL_ROOT=/opt/intel/oneapi/mkl/latest" >> "$GITHUB_ENV"
          # Robustly prepend MKL to LD_LIBRARY_PATH for subsequent steps in this job
          MKL_LD_PATH="/opt/intel/oneapi/mkl/latest/lib/intel64"
          if [ -n "$LD_LIBRARY_PATH" ]; then
            echo "LD_LIBRARY_PATH=${MKL_LD_PATH}:${LD_LIBRARY_PATH}" >> "$GITHUB_ENV"
          else
            echo "LD_LIBRARY_PATH=${MKL_LD_PATH}" >> "$GITHUB_ENV"
          fi

      - name: Cache Cargo dependencies
        uses: actions/cache@v4
        id: cache-cargo-deps
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
          key: ${{ runner.os }}-cargo-deps-${{ hashFiles('**/Cargo.lock') }}-${{ matrix.blas_backend }}-${{ matrix.rust_flags }}
          restore-keys: |
            ${{ runner.os }}-cargo-deps-${{ hashFiles('**/Cargo.lock') }}-${{ matrix.blas_backend }}-
            ${{ runner.os }}-cargo-deps-

      - name: Cache Rust target directory
        uses: actions/cache@v4
        id: cache-rust-target
        with:
          path: target
          key: ${{ runner.os }}-target-${{ steps.rust_version.outputs.version }}-${{ hashFiles('**/Cargo.lock') }}-${{ hashFiles('**/src/**/*.rs', '**/examples/**/*.rs', '**/tests/**/*.rs', '**/benches/**/*.rs', '**/lib.rs', '**/main.rs', '**/build.rs') }}-${{ matrix.blas_backend }}-${{ matrix.rust_flags }}
          restore-keys: |
            ${{ runner.os }}-target-${{ steps.rust_version.outputs.version }}-${{ hashFiles('**/Cargo.lock') }}-${{ matrix.blas_backend }}-
            ${{ runner.os }}-target-${{ steps.rust_version.outputs.version }}-${{ matrix.blas_backend }}-
            ${{ runner.os }}-target-

      - name: Build ðŸ› ï¸ (${{ matrix.blas_backend }})
        run: cargo build --verbose --release --features ${{ matrix.backend_feature }}
        env:
          RUSTFLAGS: ${{ matrix.rust_flags }}
          LD_LIBRARY_PATH: ${{ env.LD_LIBRARY_PATH }} # Inherits job's LD_LIBRARY_PATH (MKL aware if set)

      - name: Run tests ðŸ§ª (${{ matrix.blas_backend }})
        run: cargo test --verbose --features ${{ matrix.backend_feature }}
        env:
          RUSTFLAGS: ${{ matrix.rust_flags }}
          LD_LIBRARY_PATH: ${{ env.LD_LIBRARY_PATH }} 
          RUST_BACKTRACE: 1
      
      - name: Run benchmarks (${{ matrix.blas_backend }})
        run: cargo bench --features ${{ matrix.backend_feature }}
        env:
          RUSTFLAGS: ${{ matrix.rust_flags }}
          LD_LIBRARY_PATH: ${{ env.LD_LIBRARY_PATH }} 
          RUST_BACKTRACE: 1

      # --- getdoc Integration on Failure ---
      - name: Install getdoc on failure
        if: failure() 
        run: cargo install getdoc --locked # Use --locked for more reproducible installs from crates.io

      - name: Run getdoc for ${{ matrix.backend_feature }} context on failure
        if: failure()
        # RUSTFLAGS and LD_LIBRARY_PATH for the current matrix leg are inherited from the job environment
        run: getdoc --features ${{ matrix.backend_feature }} # Generates 'report.md'

      - name: Rename getdoc report for this backend
        if: failure()
        run: mv report.md report-${{ runner.os }}-${{ matrix.blas_backend }}.md

      - name: Upload getdoc report for this backend
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: getdoc-report-${{ runner.os }}-${{ matrix.blas_backend }} 
          path: report-${{ runner.os }}-${{ matrix.blas_backend }}.md
          if-no-files-found: error # The report should exist if getdoc ran

  summarize_and_create_issue:
    name: Summarize Reports and Manage Issues
    runs-on: ubuntu-latest
    needs: build_test_bench 
    if: failure() # Runs only if any build_test_bench matrix job failed
    steps:
      - name: Create workspace for downloaded artifacts
        run: mkdir -p all_getdoc_reports

      - name: Download all getdoc reports
        uses: actions/download-artifact@v4
        with:
          path: all_getdoc_reports # Downloads all artifacts from the run into this directory

      - name: Consolidate getdoc reports
        id: consolidate 
        run: |
          FINAL_REPORT_FILE="final_consolidated_report.md"
          # Initialize the report with a header
          echo "## Consolidated getdoc Failure Report - Workflow Run: ${{ github.run_id }}" > ${FINAL_REPORT_FILE}
          echo "Commit: ${{ github.sha }}" >> ${FINAL_REPORT_FILE}
          echo "Timestamp: $(date -u +"%Y-%m-%dT%H:%M:%SZ")" >> ${FINAL_REPORT_FILE}
          echo "" >> ${FINAL_REPORT_FILE}

          NUM_REPORTS_PROCESSED=0
          # Process each downloaded report file
          # The find command with -print0 and while read -d $'\0' is robust for various filenames.
          find all_getdoc_reports -type f -name "report-*.md" -print0 | while IFS= read -r -d $'\0' report_file; do
            echo "Processing found report file: ${report_file}" # For debugging
            ARTIFACT_CONTEXT=$(basename "$(dirname "${report_file}")") # Extracts artifact name like 'getdoc-report-Linux-backend_mkl'
            
            echo "---" >> ${FINAL_REPORT_FILE}
            echo "### Report from Artifact: ${ARTIFACT_CONTEXT}" >> ${FINAL_REPORT_FILE}
            echo "(Original file path in runner: ${report_file})" >> ${FINAL_REPORT_FILE}
            echo "" >> ${FINAL_REPORT_FILE}
            cat "${report_file}" >> ${FINAL_REPORT_FILE}
            echo "" >> ${FINAL_REPORT_FILE} 
            echo "" >> ${FINAL_REPORT_FILE} 
          done

          # After the loop, count how many actual report sections were added
          NUM_REPORTS_PROCESSED=$(grep -c "### Report from Artifact:" "${FINAL_REPORT_FILE}")

          if [ "${NUM_REPORTS_PROCESSED}" -gt "0" ]; then
            echo "Successfully consolidated ${NUM_REPORTS_PROCESSED} getdoc report(s) into ${FINAL_REPORT_FILE}."
          else
            echo "No individual getdoc reports found to consolidate. Appending fallback message."
            # Fallback message if no reports were processed by the loop
            echo "" >> ${FINAL_REPORT_FILE} # Ensure a blank line before fallback section
            echo "## CI Failure - No specific getdoc Reports Found or Processed" >> ${FINAL_REPORT_FILE}
            echo "Workflow run ${{ github.run_id }} for commit ${{ github.sha }} on ref ${{ github.ref }} failed." >> ${FINAL_REPORT_FILE}
            echo "Although the summarization job was triggered, the script could not find or process individual 'getdoc' report artifacts from the 'all_getdoc_reports' directory." >> ${FINAL_REPORT_FILE}
            echo "Listing contents of 'all_getdoc_reports' for debugging:" >> ${FINAL_REPORT_FILE}
            ls -R all_getdoc_reports >> ${FINAL_REPORT_FILE}
            echo "" >> ${FINAL_REPORT_FILE}
            echo "Please check the logs of the 'build_test_bench' job legs for direct error details and individual artifact upload status." >> ${FINAL_REPORT_FILE}
          fi
          
          echo "--- Preview of Consolidated Report (first 50 lines) ---"
          head -n 50 ${FINAL_REPORT_FILE}
          echo "--------------------------------------------------------"

      - name: Display full consolidated report content in logs
        run: cat final_consolidated_report.md 

      - name: Upload consolidated getdoc report
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-getdoc-report
          path: final_consolidated_report.md 

      - name: Auto-close old automated issues
        if: github.event_name == 'push' && github.ref == 'refs/heads/main' 
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            const labelsToMatch = ['getdoc', 'automated-report']; 
            const twentyFourHoursInMs = 24 * 60 * 60 * 1000;
            const cutOffDate = new Date(new Date().getTime() - twentyFourHoursInMs);

            core.info(`Searching for open issues with labels: ${labelsToMatch.join(', ')} created before ${cutOffDate.toISOString()}`);

            const { data: issues } = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: labelsToMatch.join(','), 
            });

            let closedCount = 0;
            for (const issue of issues) {
              // Additional check: ensure title matches the automated report format to be safer
              if (!issue.title.startsWith("Automated CI Failure Report - Workflow Run")) {
                core.info(`Skipping issue #${issue.number} ('${issue.title}') as its title does not match the expected pattern for automated reports.`);
                continue;
              }
              const createdAt = new Date(issue.created_at);
              if (createdAt < cutOffDate) {
                core.info(`Closing issue #${issue.number} ('${issue.title}') as it was created at ${createdAt.toISOString()} (older than 24 hours).`);
                try {
                  await github.rest.issues.update({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: issue.number,
                    state: 'closed'
                  });
                  closedCount++;
                } catch (error) {
                  core.error(`Failed to close issue #${issue.number}: ${error.message}`);
                }
              } else {
                core.info(`Issue #${issue.number} ('${issue.title}') was created at ${createdAt.toISOString()}, not old enough to close.`);
              }
            }
            if (closedCount > 0) {
              core.info(`Successfully closed ${closedCount} old automated issue(s).`);
            } else {
              core.info("No old automated issues found matching criteria to close.");
            }

      - name: Create New GitHub Issue with consolidated report
        if: github.event_name == 'push' && github.ref == 'refs/heads/main' 
        uses: peter-evans/create-issue-from-file@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          title: "Automated CI Failure Report - Workflow Run ${{ github.run_id }}"
          content-filepath: ./final_consolidated_report.md 
          labels: bug, ci-failure, automated-report, getdoc
